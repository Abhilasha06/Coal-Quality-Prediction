{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Abhilasha\\Anaconda2\\envs\\tensorflow_env\\lib\\site-packages\\skimage\\external\\tifffile\\tifffile.py:305: UserWarning: ImportError: No module named '_tifffile'. Loading of some compressed images will be very slow. Tifffile.c can be obtained at http://www.lfd.uci.edu/~gohlke/\n",
      "  \"ImportError: No module named '_tifffile'. \"\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import graph_util\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from skimage.io import imshow\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from sklearn.utils import shuffle\n",
    "import numpy.random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1='D://fintest//1coal'\n",
    "data2='D://fintest//2coal'\n",
    "data3='D://fintest//3coal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_with_label():\n",
    "    images=[]\n",
    "    cnt = 0\n",
    "    for i in tqdm(os.listdir(data1)):\n",
    "        path=os.path.join(data1,i)\n",
    "        img=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img=cv2.resize(img,(64,64))\n",
    "        images.append([np.array(img),'0'])\n",
    "    cnt = 0\n",
    "    for i in tqdm(os.listdir(data2)):\n",
    "        path=os.path.join(data2,i)\n",
    "        img=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img=cv2.resize(img,(64,64))\n",
    "        images.append([np.array(img),'1'])\n",
    "    cnt = 0\n",
    "    for i in tqdm(os.listdir(data3)):\n",
    "        path=os.path.join(data3,i)\n",
    "        img=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img=cv2.resize(img,(64,64))\n",
    "        images.append([np.array(img),'2'])\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 390/390 [00:21<00:00, 15.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 299/299 [00:17<00:00, 17.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 455/455 [00:31<00:00, 12.12it/s]\n"
     ]
    }
   ],
   "source": [
    "data = data_with_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.shuffle(data)\n",
    "x_train = np.array([i[0] for i in data]).reshape(-1,64,64,1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "y_train = np.array([i[1] for i in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have a total of 1154 images taking 500 to generate valid training pairs\n",
    "image_list = np.split(x_train[:500],500)\n",
    "label_list = np.split(y_train[:500],500)\n",
    "\n",
    "left_input = []\n",
    "right_input = []\n",
    "targets = []\n",
    "\n",
    "#every single image will be paired with 10 dustinct images along with the label 1 if they match else the label 0\n",
    "pairs = 10\n",
    "#total number of training pairs generated will be 5000 (500*10)\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    for _ in range(pairs):\n",
    "        compare_to = i\n",
    "        while compare_to == i: #to make sure it's not comparing with itself\n",
    "            compare_to = random.randint(0,499)\n",
    "        left_input.append(image_list[i])\n",
    "        right_input.append(image_list[compare_to])\n",
    "        if label_list[i] == label_list[compare_to]:\n",
    "            targets.append(1.)\n",
    "        else:\n",
    "            targets.append(0.)\n",
    "            \n",
    "left_input = np.squeeze(np.array(left_input))\n",
    "right_input = np.squeeze(np.array(right_input))\n",
    "targets = np.squeeze(np.array(targets))\n",
    "\n",
    "#taking a random image from the traing set and finding its correct pairs from the testing set\n",
    "img1 = x_train[68]\n",
    "#total number of testing pairs will be (1154-500)*1 thai is 654 pairs\n",
    "test_left = []\n",
    "test_right = []\n",
    "test_targets = []\n",
    "\n",
    "for i in range(y_train.shape[0]-500):\n",
    "    test_left.append(img1)\n",
    "    test_right.append(x_train[i+500])\n",
    "    if y_train[68]==y_train[i+500]:\n",
    "        test_targets.append(1.)\n",
    "    else:\n",
    "        test_targets.append(0.)\n",
    "\n",
    "test_left = np.squeeze(np.array(test_left))\n",
    "test_right = np.squeeze(np.array(test_right))\n",
    "test_targets = np.squeeze(np.array(test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1144, 64, 64, 1)\n",
      "(644, 64, 64, 1)\n",
      "(644, 64, 64, 1)\n",
      "(5000, 64, 64, 1)\n",
      "(5000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "test_right = np.array([i for i in test_right]).reshape(-1,64,64,1)\n",
    "test_left = np.array([i for i in test_left]).reshape(-1,64,64,1)\n",
    "left_input = np.array([i for i in left_input]).reshape(-1,64,64,1)\n",
    "right_input = np.array([i for i in right_input]).reshape(-1,64,64,1)\n",
    "print(x_train.shape)\n",
    "print(test_right.shape)\n",
    "print(test_left.shape)\n",
    "print(left_input.shape)\n",
    "print(right_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking two images to check their similarity\n",
    "def create_model():\n",
    "\n",
    "    left_input = Input((64,64,1))\n",
    "    right_input = Input((64,64,1))\n",
    "\n",
    "# Base network architecture\n",
    "\n",
    "    convnet=Sequential()\n",
    "    convnet.add(InputLayer(input_shape=[64,64,1]))\n",
    "    convnet.add(Conv2D(filters=32,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "    convnet.add(MaxPool2D(pool_size=5,padding='same'))   \n",
    "    convnet.add(Conv2D(filters=32,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "    convnet.add(MaxPool2D(pool_size=5,padding='same'))  \n",
    "    convnet.add(Conv2D(filters=64,kernel_size=3,strides=1,padding='same',activation='relu'))\n",
    "    convnet.add(MaxPool2D(pool_size=8,padding='same'))\n",
    "    convnet.add(Conv2D(filters=128,kernel_size=3,strides=1,padding='same',activation='relu'))\n",
    "    convnet.add(MaxPool2D(pool_size=5,padding='same'))   \n",
    "    convnet.add(Conv2D(filters=256,kernel_size=3,strides=1,padding='same',activation='relu'))\n",
    "    convnet.add(Flatten())\n",
    "\n",
    "    convnet.add(Dense(1024,activation='relu'))\n",
    "    convnet.add(Dropout(0.20))\n",
    "    convnet.add(Dense(512,activation='relu'))\n",
    "    convnet.add(Dropout(0.25))\n",
    "    convnet.add(Dense(64,activation='sigmoid'))\n",
    "\n",
    "#generating the encodings for two input images\n",
    "    encoded_l = convnet(left_input)\n",
    "    encoded_r = convnet(right_input)\n",
    "\n",
    "# Getting the L1 Distance between the 2 encodings\n",
    "    L1_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n",
    "\n",
    "# Add the distance function to the network\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "\n",
    "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "    optimizer = Adam(0.0001, decay=2.5e-4)\n",
    "    siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['accuracy'])\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model, accuracy: 41.61%\n"
     ]
    }
   ],
   "source": [
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Evaluate the model\n",
    "loss, acc = model.evaluate([test_left,test_right], test_targets, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model, accuracy: 94.41%\n"
     ]
    }
   ],
   "source": [
    "# Loads the weights\n",
    "checkpoint_path='cpss2.ckpt'\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate([test_left,test_right], test_targets, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5754501]]\n",
      "[[0.00064226]]\n",
      "[[6.975044e-08]]\n"
     ]
    }
   ],
   "source": [
    "#images from 3 classes \n",
    "left= cv2.imread(\"D://fintest//1coal//pic1crop.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "left= cv2.resize(left,(64,64))\n",
    "left=np.array(left).reshape(-1,64,64,1)\n",
    "left= left/255\n",
    "\n",
    "left1= cv2.imread(\"D://fintest//2coal//pic1crop.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "left1= cv2.resize(left1,(64,64))\n",
    "left1=np.array(left1).reshape(-1,64,64,1)\n",
    "left1= left1/255\n",
    "\n",
    "left2= cv2.imread(\"D://fintest//3coal//pic1crop.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "left2= cv2.resize(left2,(64,64))\n",
    "left2=np.array(left2).reshape(-1,64,64,1)\n",
    "left2= left2/255\n",
    "\n",
    "#test image from class 1\n",
    "right= cv2.imread(\"D://fintest//1coal//pic7crop.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "right=cv2.resize(right,(64,64))\n",
    "right=np.array(right).reshape(-1,64,64,1)\n",
    "right= right/255\n",
    "\n",
    "\n",
    "print(model.predict([left,right]))\n",
    "print(model.predict([left1,right]))\n",
    "print(model.predict([left2,right]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
